\documentclass{article}

% use Times
\usepackage{times}
% For figures
\usepackage{graphicx} % more modern
%\usepackage{subfigure} 
\usepackage{subcaption}


% For citations
\usepackage{natbib}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

% As of 2011, we use the hyperref package to produce hyperlinks in the
% resulting PDF.  If this breaks your system, please commend out the
% following usepackage line and replace \usepackage{icml2016} with
% \usepackage[nohyperref]{icml2016} above.
\usepackage{hyperref}

% Packages hyperref and algorithmic misbehave sometimes.  We can fix
% this with the following command.
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Employ the following version of the ``usepackage'' statement for
% submitting the draft version of the paper for review.  This will set
% the note in the first column to ``Under review.  Do not distribute.''
\usepackage{icml2016} 
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{dsfont}
\usepackage{booktabs}
\usepackage{relsize}
\usepackage{lmodern}
\usepackage{slantsc}
\usepackage{siunitx}
\sisetup{output-exponent-marker=\ensuremath{\mathrm{E}}}


\newcommand{\xsj}{\mathbf{\hat{x}}_j}
\newcommand{\xuj}{\mathbf{x}_j}
\newcommand{\xsi}{\mathbf{\hat{x}}_i}
\newcommand{\xui}{\mathbf{x}_i}
\newcommand{\ysi}{\hat{y}_i}
\newcommand{\ysj}{\hat{y}_j}
\newcommand{\yui}{y_i}
\newcommand{\sw}{s_{ \textsc{\relsize{-2}{\textsl{W}}} }}



% Employ this version of the ``usepackage'' statement after the paper has
% been accepted, when creating the final version.  This will set the
% note in the first column to ``Proceedings of the...''
%\usepackage[accepted]{icml2016}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Transductive Unsupervised Domain Adaptation}

\begin{document} 

\twocolumn[
\icmltitle{Transductive Unsupervised Domain Adaptation}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2016
% package.
\icmlauthor{Ozan Sener}{ozansener@cs.stanford.edu}
\icmladdress{Stanford University,
		     Stanford, CA 94304, USA}
		     \vspace{-2mm}
\icmladdress{Cornell University,
		     Ithaca, NY 14853, USA}
\icmlauthor{Hyun Oh Song}{hsong@cs.stanford.edu}
\icmladdress{Stanford University,
		     Stanford, CA 94304, USA}

\icmlauthor{Silvio Savarese}{ssilvio@stanford.edu}
\icmladdress{Stanford University,
		     Stanford, CA 94304, USA}
\icmlauthor{Ashutosh Saxena}{ashutosh@brainoft.com}
\icmladdress{Brain of Things,
		     Cupertino, CA 94304, USA}


% You may provide any keywords that you 
% find helpful for describing your paper; these are used to populate 
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{domain adaptation, transductive learning, metric learning, deep learning}

\vskip 0.3in
]

\begin{abstract} 
Recently, supervised learning with large scale labeled datasets and deep layered models has made a paradigm shift in diverse areas in learning and recognition. However, this approach still suffers generalization issues under the presence of a domain shift between the training and the test data distribution. In this regard, unsupervised domain adaptation algorithms have been proposed to directly address the domain shift problem. In this paper, we approach the problem from a transductive perspective. We incorporate the domain shift and the transductive target inference into our framework by jointly solving for an asymmetric similarity metric and the optimal transductive target label assignment. We also show that our model can easily be extended for deep feature learning in order to learn features which are discriminative in the target domain. Our experiments show that the proposed method significantly outperforms state-of-the-art algorithms in both object recognition and digit classification experiments by a large margin.
\end{abstract} 

\section{Introduction}
\label{intro}
Recently deep convolutional neural networks \cite{alexnet, vggnet, googlenet} have propelled unprecedented advances in artificial intelligence including object recognition, speech recognition, and image captioning. One of the major drawbacks of the method is that the network requires a lot of labelled training data to fit millions of parameters in the complex network model. However, creating such datasets with complete annotations is not only tedious and error prone but also extremely costly. In this regard, the research community have proposed different mechanisms such as semi-supervised learning \cite{semisup1,semisup2,semisup3}, transfer learning \cite{transfer1, transfer2}, weakly labelled learning, and domain adaptation. Of the approaches, domain adaptation is one of the most appealing techniques when a fully annotated dataset (i.e. ImageNet \cite{ImageNet}, Sports1M \cite{sports1m}) is available as a reference. 

Formally, the goal of unsupervised domain adaptation is: given a fully labeled source dataset and a unlabeled target dataset, learning a model which can generalize to the target domain while taking the domain shift across the datasets into account. The majority of the literature \cite{gong12, baochen15, fernando13, baochen16, tommasi13} in unsupervised domain adaptation formulates a learning problem where the task is to find a transformation matrix to align the labelled source data distribution to the unlabelled target data distribution. Although these approaches show promising results, it does not take the actual target inference procedure into the learning algorithm. We solve this problem by incorporating the unknown target labels into the training procedure.

Concretely, we formulate a unified framework where the domain transformation parameter and the target labels are jointly optimized in two alternating stages. In the transduction stage, given a fixed domain transform parameter, we jointly infer all target labels by solving a discrete multi-label energy minimization problem. In the adaptation stage, given a fixed target label assignment, we seek to find the optimal asymmetric metric  between the source and the target data. The advantage of the method is that the we can learn a domain transformation parameter which is aware of the subsequent transductive inference procedure. 

Following the standard evaluation protocol in the domain adaptation community, we evaluate our method on the digit classification task using MNIST \cite{mnist} and SVHN\cite{svhn} as well as the object recognition task using the Office \cite{office} dataset, and demonstrate state of the art performance in comparison to all existing unsupervised domain adaptation methods.  We will make our learned models as well as the source code available immediately upon acceptance.

\section{Related Work} 

This paper is closely related to two active research areas: (1) Unsupervised domain adaptation, and (2) Transductive learning.

\textbf{Unsupervised domain adaptation}: \cite{gong12, baochen15, fernando13, baochen16} proposed subspace alignment based approaches to unsupervised domain adaptation where the task is to learn a joint transformation and projection where the difference between the source and the target covariance is minimized. However, these methods learn the transform matrices on the whole source and target dataset without utilizing the the source labels. 

\cite{tommasi13} utilizes local max margin metric learning objective \cite{lmnn} to first assign the target labels with nearest neighbor scheme and then learn a distance metric to enforce that the negative pairwise distances are larger than the positive pairwise distances with a margin. However, this method learns a symmetric distance matrix shared by both the source and the target domains so the method is susceptible to the discrepancies between the source and the target distributions. Recently, \cite{ganin15, tzeng14} proposed a deep learning based method to learn domain invariant features via providing the reversed gradient signal from the binary domain classifiers. Although they perform better than aforementioned approaches, their accuracy is limited since domain invariance does not necessarily imply discriminative features in the target domain. 

\textbf{Transductive learning}: In the transductive learning literature \cite{transduction}, the model has access to unlabelled test samples during training. Recently, \cite{coclassification} tackled a classification problem where predictions are made jointly across all test examples in a transductive \cite{transduction} setting. The method essentially enforces the notion that the true labels vary smoothly with respect to the input data. In our work, we extend this notion to infer the multiclass labels of unsupervised target data in a k-NN graph. 

To summarize, our main contribution is to formulate joint optimization framework where we alternate between inferring target labels via discrete energy minimization (\textit{transduction}) and learning an asymmetric transformation (\textit{adaptation}) between source and target examples. Our experiments on digit classification using MNIST \cite{mnist} and SVHN\cite{svhn} as well as the object recognition experiments on Office \cite{office} datasets show state of the art results outperforming all existing methods by a substantial margin.


\section{Method} 
\input{method.tex}


\section{Experimental Results}
\input{exp.tex}
\section{Conclusion} 
We described a transductive approach to the unsupervised domain adaptation problem by defining a joint learning problem on the transductive target label assignment and a asymmetric similarity metric across the domains. We further described a method to learn deep features which are discriminative in the target domain. Experimental results on digit classification using MNIST\cite{mnist} and SVHN\cite{svhn} as well as on object recognition using Office\cite{office} dataset show state of the art performance with a significant margin. We will make our learned models as well as the source code available immediately upon acceptance.



\clearpage
\bibliography{domain_transduction}
\bibliographystyle{icml2016}

\end{document} 